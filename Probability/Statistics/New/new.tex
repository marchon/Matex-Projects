
\documentclass[../Main/main]{subfiles}


\begin{document}


\unit{ $ New $ }
{
	

	\definition{ $ UMV $ }
	{
		\letbe
		{
			statements.
		}
		\then{ item }{ $ a/an entity $ }
		{
			conditions.
		}
		\denote
		{
			property \as notation.
		}
	}
	
	
	\definition{ $ Efficient $ }
	{
		\letbe
		{
			( \Omega, \Ac, \Pc ) $ parametric statistical model $.
			\function{ X }{ \Omega }{ \R } $ random variable $.
			\Theta \subset \R $ interval $.
			\chi_F $ real estimator with integrable quadratic $.
		}
		\then{ item }{ $ a/an entity $ }
		{
			\all{ \theta \in \Theta }
			{
				\ex{ \function{ h }{ \R }{ \R } }
				{
					h \geq 0.
					h $ integrable $.
					\ex{ \Uc \subset \R }
					{
						\theta \in \Uc.
						|T(x) \partialderivative{ L(x,\theta) }{ \theta }| \leq h
					}
				}
			}
		}
	}
	

	\proposition{ $ Cramer-Rao's inequality $ }
	{
		\letbe
		{
			$ same conditions of above $.
			T \in \chi_F.
			$ regular model $.
			E_\theta T = g(\theta)		
		}
		\holds
		{
			Var_\theta ( T ) \geq \frac{ g'(\theta)^2 }{ I(\theta) }
		}
		\demonstration
		{
			|E( \partialderivative{ \log( L(x,\theta) )(T(x)-g(\theta) }{ \theta }| \leq \sqrt{ E_\theta( \partialderivative{ \log( L(x,\theta) ) }{ \theta })^2 E_\theta(T(x)-g(\theta))^2} = \sqrt{ I(\theta)Var_\theta T } .

			E( \partialderivative{ \log( L(x,\theta) )(T(x)g(\theta) }{ \theta } = E_\theta(\partialderivative{ \log( L(x,\theta)T(x) ) }{ \theta } - g(\theta)E_\theta(\partialderivative{ \log( L(x,\theta) ) }{ \theta } = E_\theta(\partialderivative{ \log( L(x,\theta)T(x) ) }{ \theta }.

			\integral{ \partialderivative{ \log( L(x,\theta) ) }{ \theta }T(x) L(x,\theta) }{ dx }{ \Omega } = \integral{ \frac{ 1 }{ L(x,\theta) }\partialderivative{ L(x,\theta) }{ \theta }T(x)L(x,\theta) }{ dx }{ \Omega }.

			|g'(\theta)| \leq \sqrt{ I(\theta)Var_\theta(T) }.

			g'(\theta)^2 \leq I(\theta)Var_\theta(T)
		}
	}
	
	
	\definition{ $ Efficient $ }
	{
		\letbe
		{
			$mismas condiciones$
		}
		\then{ T }{ $ efficient $ }
		{
			Var_\theta T = \frac{ g'(\theta)^2 }{ I(\theta) }
		}
	}
	
	
	\proposition{ $ Efficient estimators are UMV $ }
	{
		\letbe
		{
			statements.
		}
		\holds
		{
			then, holds.
		}
		\demonstration
		{
			demonstration.
		}
	}
	
	
	\proposition{ $ Characterization of efficient estimators $ }
	{
		\letbe
		{
			$ mismas condiciones $
		}
		\holds
		{
			T $ efficient $ \ifandonlyif \ex{ \lambda(\theta) }
			{
				\lambda(\theta)\partialderivative{ \log( L(x,\theta) }{ \theta } = T(x) - g(\theta) P_\theta-qs
			}
		}
		\demonstration
		{
			$ no demonstration $
		}
	}
	
	
	\proposition{ $ Observation $ }
	{
		\letbe
		{
			$ mismas condiciones $
		}
		\holds
		{
			
		}
		\demonstration
		{
			\lambda'(\theta)\log( L(x,\theta) ) + \lambda(\theta)\partialderivative{ \log( L(x,\theta) ) }{ \theta^2 } = - g'(\theta).

			E[*] = E_\theta(\lambda(\theta)\partialderivative{ \log( L(x,\theta) ) }{ \theta }) + \lambda(\theta)E_\theta( \partialderivative{ \log( L(x,\theta) ) }{ \theta^2 }) = 0 - g'(\theta).
			\lambda(\theta)I(\theta) = g'(\theta).
			I(\theta) = \frac{ g'(\theta) }{ \lambda(\theta) }
		}
	}
	
	
	
	
	
	
	si existe un estimador que da la igualdad entonces es UMV
	
	

	
}


\end{document}